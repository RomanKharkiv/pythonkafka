services:

  # Catalog UI

  # lrl-urpid-catalog:
  #   image: 'lrl-urpid-catalog:latest'
  #   depends_on:
  #     - lrl-urpid-core
  #   build:
  #     dockerfile: ./container/Dockerfile_consumer_avro
  #     context: ..
  #   ports:
  #     - "8082:80"
  #   volumes:
  #     - type: bind
  #       source: ./configs/config.js
  #       target: /usr/share/nginx/html/config.js

  # Core
  
  # lrl-urpid-core:
    # TODO: use elilly docker registry to avoid build constantly
    # image: 'lrl-urpid-core:latest'
    # depends_on: 
    #   - kafka
    #   - postgres
    # build:
    #   dockerfile: ./container/Dockerfile_consumer_avro
    #   # TODO: change branch
    #   context: ${GIT_PREFIX}EliLillyCo/LRL_urpid_core.git#dev
    # environment:
    #   - APP_PORT=8080
    #   - DATABASE_URL=jdbc:postgresql://postgres:5432/${POSTGRES_DB}
    #   - DATABASE_SCHEMA=urpid
    #   - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    #   - LIQUIBASE_CONTEXT=dev
    # ports: 
    #   - "8081:8080"

  # Database
  postgres:
    image: postgres:${POSTGRES_VERSION}
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    expose:
      - "5432"
  #   volumes:
  #     - postgres-data:/var/lib/postgresql/data

  ## Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    expose:
      - "2181"

  kafka-broker-1:
    image: confluentinc/cp-kafka:latest
    hostname: kafka-broker-1
    ports:
      - "19092:19092"
      - "9997:9997"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-1:9092,PLAINTEXT_INTERNAL://localhost:19092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka-broker-1 -Dcom.sun.management.jmxremote.rmi.port=9997
      KAFKA_MESSAGE_MAX_BYTES: 5242880  # 5 MB
      KAFKA_MAX_REQUEST_SIZE: 5242880  # 5 MB for producer requests


  kafka-broker-2:
    image: confluentinc/cp-kafka:latest
    hostname: kafka-broker-2
    ports:
      - "29092:29092"
      - "9998:9998"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-2:9092,PLAINTEXT_INTERNAL://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_JMX_PORT: 9998
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka-broker-1 -Dcom.sun.management.jmxremote.rmi.port=9998
      KAFKA_MESSAGE_MAX_BYTES: 5242880  # 5 MB
      KAFKA_MAX_REQUEST_SIZE: 5242880  # 5 MB for producer requests


  kafka-broker-3:
    image: confluentinc/cp-kafka:latest
    hostname: kafka-broker-3
    ports:
      - "39092:39092"
      - "9999:9999"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker-3:9092,PLAINTEXT_INTERNAL://localhost:39092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka-broker-3 -Dcom.sun.management.jmxremote.rmi.port=9999
      KAFKA_MESSAGE_MAX_BYTES: 5242880  # 5 MB
      KAFKA_MAX_REQUEST_SIZE: 5242880  # 5 MB for producer requests

  ## Kafka Topics initialization
  kafka-init-topics:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
             cub kafka-ready -b kafka-broker-1:9092 1 30 && \
             kafka-topics --create --topic object.gsmr --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka-broker-1:9092 && \
             kafka-topics --create --topic object.regmol --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka-broker-1:9092 && \
             kafka-topics --create --topic object.benchling --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka-broker-1:9092 && \
             kafka-topics --create --topic result.gsmr --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka-broker-1:9092 && \
             kafka-topics --create --topic result.regmol --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka-broker-1:9092 && \
             kafka-topics --create --topic result.benchling --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka-broker-1:9092 && \
             kafka-topics --create --topic result.overall.proto --partitions 3 --replication-factor 2 --if-not-exists --bootstrap-server kafka-broker-3:9092 && \
             kafka-topics --create --topic result.overall.avro --partitions 3 --replication-factor 2 --if-not-exists --bootstrap-server kafka-broker-2:9092 && \
             kafka-topics --create --topic result.overall --partitions 3 --replication-factor 2 --if-not-exists --bootstrap-server kafka-broker-1:9092'"


  ## Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8080:8080"
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
      - schemaregistry
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-broker-1:9092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schemaregistry:8085
      KAFKA_CLUSTERS_0_METRICS_PORT: 9997
      KAFKA_CLUSTERS_1_NAME: local2
      KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS: kafka-broker-2:9092
      KAFKA_CLUSTERS_1_SCHEMAREGISTRY: http://schemaregistry:8085
      KAFKA_CLUSTERS_1_METRICS_PORT: 9998
      KAFKA_CLUSTERS_2_NAME: Local3
      KAFKA_CLUSTERS_2_BOOTSTRAPSERVERS: kafka-broker-3:9092
      KAFKA_CLUSTERS_2_SCHEMAREGISTRY: http://schemaregistry:8085
      KAFKA_CLUSTERS_2_METRICS_PORT: 9999
      DYNAMIC_CONFIG_ENABLED: 'true'

  schemaregistry:
    image: confluentinc/cp-schema-registry:7.2.1
    ports:
      - 8085:8085
    depends_on:
      - kafka-broker-1
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka-broker-1:9092
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry
      SCHEMA_REGISTRY_LISTENERS: http://schemaregistry:8085

      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas

  ## Kafka producer with fake egress messages
  producer:
    build:
      context: .
      dockerfile: docker/Dockerfile_producer
    container_name: producer
    image: my/kafka-producer:v1
    environment:
      KAFKA_TOPIC: result.overall
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    restart: on-failure

  ## Kafka consumer
  consumer:
    build:
      dockerfile: docker/Dockerfile_consumer
    image: my/kafka-consumer:v1
    environment:
      KAFKA_TOPIC: result.overall
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    restart: on-failure
    scale: 3

  produce_proto:
    build:
      dockerfile: docker/Dockerfile_producer_proto
    image: my/producer-proto:v2
    container_name: producer_proto
    environment:
      KAFKA_TOPIC: result.overall.proto
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    restart: on-failure

  consumer_proto:
    build:
      dockerfile: docker/Dockerfile_consumer_proto
    image: my/consumer-proto:v2
    environment:
      KAFKA_TOPIC: result.overall.proto
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    restart: on-failure
    scale: 3

  produce_avro:
    build:
      dockerfile: docker/Dockerfile_producer_avro
    image: my/producer-avro:v11w
    container_name: producer_avro_451w
    environment:
      KAFKA_TOPIC: result.overall.avro
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    restart: on-failure

  consumer_avro:
    build:
      dockerfile: docker/Dockerfile_consumer_avro
    image: my/consumer-avro:v23res
    environment:
      KAFKA_TOPIC: result.overall.avro
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    depends_on:
      - kafka-broker-1
      - kafka-broker-2
      - kafka-broker-3
    restart: on-failure
    scale: 3
